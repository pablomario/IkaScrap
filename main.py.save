# Imports
import os
import sys
import random
import requests
from bs4 import BeautifulSoup
import urllib.request
import urllib.error
import pymongo
import time
import base64
import re
import unicodedata
from datetime import datetime
from colorama import Back, Style
from urllib.parse import urlparse, parse_qs


# --------------------- MAIN CONSTANTS --------------------- #

MONGODB_CHAIN = "localhost:27017"
MONGODB_DB = "ikawe"
MONGODB_BOOK_DB = "books"
MONGODB_COVERS_DB = "books_cover"

# ORIGIN-DNS = "http://9fx.us/papyrefb2_1  "
DOMAIN = "http://papyrefb53cki34wumjh2yokayxiunzmmrabpxvinfjauwm5az25snid.tor2web.it"
TARGET = "http://papyrefb53cki34wumjh2yokayxiunzmmrabpxvinfjauwm5az25snid.tor2web.it/onion_2/index.php?rn=12339"
SPAM_ASHNK = "https://ashnk.com/OTQwMDY=/"
SPAM_ANZALWEB = "https://anzalweb.ir/wp-content/uploads/2019/10/what-is-error-509-bandwidth-limit-exceeded-and-how-to-fix-it.jpg?"


def main(scrap_data=None):
    if scrap_data is None:
        scrap_latest_books()
    elif isinstance(scrap_data, dict):
        scrap_books_pages(scrap_data)
    elif isinstance(scrap_data, str):
        scrap_thematic_book(scrap_data)
    else:
        print(f'[ERROR] Parameter not valid')
    print(f'\n\n END SCRAPPING')


def scrap_latest_books():
    print(f'\n\n --------- SCRAPING LATEST BOOKS')
    scrap_target = requests.post(TARGET, headers={'User-Agent': getRandomUserAgent()})
    if scrap_target.status_code == 200:
        html_content = scrap_target.text
        scrapper(html_content)
    else:
        print('Error to load website')


def scrap_books_pages(books_payload: dict):
    print(f'\n\n --------- SCRAPING BOOK[s] PAGINATION')
    for page in range(books_payload['page_init_number'], books_payload['total_pages']):
        payload = {
            'dataGrid_page': page,
            'dataGrid_sortfield': 'anyo',
            'dataGrid_sortdirection': 'desc',
            'dataGrid_recordsOnPage': books_payload['books_x_page'],
        }
        scrap_target = requests.post(TARGET, data=payload, headers={'User-Agent': getRandomUserAgent()})
        if scrap_target.status_code == 200:
            html_content = scrap_target.text
            scrapper(html_content)
        else:
            print('Error to load website')
        print('\n\n >>>>>>>>>>>>>>')


def scrap_thematic_book(thematic: str):
    print(f'\n\n  --------- SCRAPING THEMATIC BOOK')
    payload = {
        'buska': thematic,
    }
    scrap_target = requests.post(TARGET, data=payload, headers={'User-Agent': getRandomUserAgent()})
    html_content = scrap_target.text
    scrapper(html_content)


def scrapper(html_content: str):
    # TODO - Búsqueda del libro por la tabla - Hacer algo para busqueda por URL
    response_soup = None

    try:
        response_soup = BeautifulSoup(html_content, 'html.parser')
    except urllib.error.URLError as e:
        print("Error to access URL:", str(e))
    except Exception as ex:
        print("Other app error:", str(ex))

    row_books = response_soup.find_all('tr', class_=["grid-row-odd", "grid-row-even"])
    print('Total ROW books found: ', len(row_books))

    for index_book, tr_element in enumerate(row_books, 1):
        td_elements = tr_element.find_all('td')
        if len(td_elements) >= 2:
            print('+--------------------------------------------------+')
            print('|---------- BOOK Nº: ', index_book, ' Init processing')
            book_author = td_elements[0].get_text()
            book_title = td_elements[1].get_text()
            book_unique = cleanBookName(book_title)
            print('|-- Title: ', book_title)
            print('|-- Unique: ', book_unique)

            if check_book_existence(book_unique):
                print(f'|------ ' + Back.GREEN + ' The book already exists ' + Style.RESET_ALL + ' we continue')
            else:
                book_year = td_elements[2].get_text()
                book_gender = td_elements[3].get_text()
                book_theme = td_elements[4].get_text()
                ref_link = td_elements[1].get('onclick')

                ref_link = ref_link.replace("javascript:document.location.href='..", "")
                ref_link = ref_link.replace("'", "")
                ref_link = DOMAIN + ref_link
                book_cover = {
                    'book_cover': getBookImage(ref_link)
                }

                customSleep()
                url_book_sheet = urllib.request.urlopen(ref_link)
                book_sheep_soup = BeautifulSoup(url_book_sheet, 'html.parser')
                book_summary = book_sheep_soup.find('p', class_='capitalLetter').get_text()

                button_element = None

                for link in book_sheep_soup.find_all('a', class_='myButton'):
                    if link.text == 'Mobi':
                        button_element = link
                        break
                ref_mobi = None
                ref_download = None
                ref_binary = None
                if button_element:
                    ref_mobi = button_element.get('href')
                    ref_mobi = ref_mobi.replace("./", "/")
                    ref_mobi = DOMAIN + ref_mobi
                    ref_mobi = getMobiUrl(ref_mobi)
                    ref_download = extractUrlDownloadEbook(getMobiId(ref_mobi))
                    ref_binary = getBookBinary(ref_download)

                papyro_book = {
                    'book': book_title,
                    'book_unique': book_unique,
                    'author': book_author,
                    'year': book_year,
                    'gender': book_gender,
                    'theme': book_theme,
                    'summary': book_summary,
                    'ref_download': ref_download,
                    'cover_reference': '',
                    'saved_date': datetime.now(),
                    'ref_binary': ref_binary,
                }

                print('+------ BOOK DATA --------------------------------+')
                for clave, valor in papyro_book.items():
                    customPrint(clave, valor)

                print('+------ SAVED BOOK --------------------------------+')
                print('|-- Id: ', saveBook(papyro_book, book_cover))

        print('+--------------------------------------------------+\n\n')


def getMobiUrl(url):
    customSleep()
    request = urllib.request.Request(url, headers={'User-Agent': getRandomUserAgent()})
    response = urllib.request.urlopen(request)
    nueva_url = response.geturl()
    return nueva_url


def getMobiId(url):
    customSleep()
    request = urllib.request.Request(url, headers={'User-Agent': getRandomUserAgent()})
    response = urllib.request.urlopen(request)
    book_soup = BeautifulSoup(response, 'html.parser')
    book_id = book_soup.find('a', class_='myButton', string='Mobi')['href']
    book_id = book_id.replace(SPAM_ASHNK, "")
    book_id = book_id.replace(SPAM_ANZALWEB,"")
    return book_id


def extractUrlDownloadEbook(url):
    parsed_url = urlparse(url)
    query_params = parse_qs(parsed_url.query)
    url_param_value = query_params.get('url', [])[0]
    return url_param_value


def getBookImage(cover_url):
    cover_url = cover_url.replace("/ficha2.php?a=", "/ficha/includes/")
    cover_url = cover_url.replace("&aws=", ".jpg")
    try:
        request = urllib.request.Request(cover_url, headers={'User-Agent': getRandomUserAgent()})
        response = urllib.request.urlopen(request)
        image_content = response.read()
        book_image = base64.b64encode(image_content).decode('utf-8')
    except Exception as error:
        print('[ERROR] Can not get Book Cover: ', error)
        book_image = ""
    return book_image


def saveBook(book, book_cover):
    client = pymongo.MongoClient(MONGODB_CHAIN)
    database = client[MONGODB_DB]
    collection = database[MONGODB_BOOK_DB]
    collection_covers = database[MONGODB_COVERS_DB]

    # Save Book Cover data
    result_cover = collection_covers.insert_one(book_cover)
    book["cover_reference"] = result_cover.inserted_id
    # Save Book
    result = collection.insert_one(book)
    client.close()
    return result.inserted_id


def check_book_existence(unique_book_name):
    client = pymongo.MongoClient(MONGODB_CHAIN)
    database = client[MONGODB_DB]
    collection = database[MONGODB_BOOK_DB]
    book = collection.find_one({"book_unique": unique_book_name})
    return book is not None


def getBookBinary(book_uri):
    book_name = book_uri.split("/")[-1]
    response = requests.get(book_uri)
    if response.status_code == 200:
        ruta_archivo = os.path.join("../bookhive/static/ebooks/", book_name)
        with open(ruta_archivo, 'wb') as archivo_local:
            archivo_local.write(response.content)
        print(f'|-- eBook has been download in:  {ruta_archivo}')
        return book_name
    else:
        print(f'Error to download ebook from: {book_uri} - Status Code: {response.status_code}')
        return ""


# -------------------------  FUNCIONES DE REFUERZO ---------------------


def getRandomUserAgent():
    user_agent_list = [
        "Mozilla/5.0",
        "Chrome/91.0.4472.124",
        "Safari/537.36",
        "Edge/91.0.864.59",
        "Opera/75.0.3969.149",
        "Firefox/89.0",
    ]
    random_user_agent = random.choice(user_agent_list)
    # print("User-Agent: " + random_user_agent)
    return random_user_agent


def customSleep():
    sleep_time = random.uniform(3, 7)
    time.sleep(sleep_time)


def customPrint(key, value):
    print(f'|-- ', Back.GREEN + key + Style.RESET_ALL, value)


def cleanBookName(book_name):
    book_name = book_name.lower()
    book_name = re.sub(r'[^a-z0-9]+', '-', book_name)
    book_name = re.sub(r'--+', '-', book_name)
    book_name = book_name.strip('-')
    book_name = unicodedata.normalize('NFD', book_name).encode('ascii', 'ignore').decode('utf-8')
    return book_name


"""
pages = {
    'page_init_number': 0,
    'total_pages': 50,
    'books_x_page': 32
}
main(pages)
"""


if __name__ == "__main__":
    # Comprobar si se pasó algún parámetro
    if len(sys.argv) > 1:
        # El primer argumento después del nombre del script es el parámetro que deseas pasar
        parametro = sys.argv[1]
        # Llamar a la función main y pasarle el parámetro
        main(parametro)
    else:
        main()
